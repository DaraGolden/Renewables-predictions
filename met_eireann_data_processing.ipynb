{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d51782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by unzipping each file in turn if the unzipped version does not exist already\n",
    "\n",
    "# Once the files have been unzipped read in the data as a dataframe or similar figuring out how to deal with the header properly\n",
    "\n",
    "# rewrite the data to a better format i.e cleaned data back to 2014 1st of january\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e0d6e",
   "metadata": {},
   "source": [
    "Taking zips and extracting the data to the extracted folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a6cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "for file in os.listdir('met_eireann_data/zips'):\n",
    "    if file.endswith('.zip'):\n",
    "        path_to_zip_file = os.path.join('met_eireann_data/zips', file)\n",
    "        directory_to_extract_to = os.path.join('met_eireann_data/extracted', file[:-4])  # Remove .zip extension\n",
    "        if not os.path.exists(directory_to_extract_to):\n",
    "            os.makedirs(directory_to_extract_to)\n",
    "        \n",
    "            with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "                zip_ref.extractall(directory_to_extract_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef1d12",
   "metadata": {},
   "source": [
    "Pipeline to clean data from current format to each row including the station name and all of available weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7db98797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (2,4,6,7,8,9,10,12,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly2075.csv FINNER Latitude:54.494 Longitude: -8.243 33 M (239443, 15)\n",
      "hly1575.csv MALIN HEAD Latitude:55.372 Longitude: -7.339 20 M (16828, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (2,4,6,7,8,9,10,12,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly275.csv MACE HEAD Latitude:53.326 Longitude: -9.901 21 M (193320, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (2,4,6,7,8,9,10,12,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly875.csv MULLINGAR Latitude:53.537 Longitude: -7.362 101 M (454224, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (2,4,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly1175.csv NEWPORT Latitude:53.924 Longitude: -9.573 22 M (181176, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (2,4,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly175.csv PHOENIX PARK Latitude:53.364 Longitude: -6.350 48 M (193248, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (6,12,14,15,16,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly518.csv SHANNON AIRPORT Latitude:52.690 Longitude: -8.918 15 M (701280, 21)\n",
      "hly1275.csv MARKREE Latitude:54.175 Longitude: -8.456 34 M (178152, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (2,4,6,7,8,9,10,12,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly1875.csv ATHENRY Latitude:53.289 Longitude: -8.786 40 M (136008, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (2,4,6,7,8,9,10,12,14,15,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly2275.csv VALENTIA OBSERVATORY Latitude:51.938 Longitude: -10.241 24 M (707112, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (2,4,6,7,8,9,10,12,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly1775.csv JOHNSTOWN CASTLE 2 Latitude:52.298 Longitude: -6.497 62 M (193344, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (2,4,6,7,8,9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly1475.csv GURTEEN Latitude:53.035 Longitude: -8.009 75 M (154224, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (2,4,6,7,8,9,10,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly775.csv SHERKIN ISLAND Latitude:51.476 Longitude: -9.428 21 M (187056, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1219256751.py:22: DtypeWarning: Columns (2,4,6,7,8,9,10,12,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hly1075.csv ROCHES POINT Latitude:51.793 Longitude: -8.244 40 M (592127, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfs = []\n",
    "for folder in os.listdir('met_eireann_data/extracted'):\n",
    "    if os.path.isdir(os.path.join('met_eireann_data/extracted', folder)):\n",
    "        for file in os.listdir(os.path.join('met_eireann_data/extracted', folder)):\n",
    "            if file.endswith('.csv'):\n",
    "                skiprows = 0\n",
    "                with open(f'met_eireann_data/extracted/{folder}/{file}', 'r') as f:\n",
    "                    for line in f:\n",
    "                        if line.startswith('Station Name'):\n",
    "                            station_name = line.split(':')[1].strip()\n",
    "                        elif line.startswith('Latitude'):\n",
    "                            Latitude = line.split(',')[0].strip()\n",
    "                            Longitude = line.split(',')[1].strip()\n",
    "                        elif line.startswith('Station Height'):\n",
    "                            Station_Height = line.split(':')[1].strip()\n",
    "                        elif line.split(',')[0] == 'date':\n",
    "                            break\n",
    "                        elif line.split(',')[0] == 'date':\n",
    "                            break\n",
    "                        skiprows += 1\n",
    "                df = pd.read_csv(f'met_eireann_data/extracted/{folder}/{file}', skiprows=skiprows)\n",
    "                dfs.append((df, station_name, Latitude, Longitude, Station_Height, file))\n",
    "\n",
    "                # with open(f'met_eireann_data/extracted/{folder}/{file[:-4]}.txt', 'w') as f:\n",
    "                #     with open(f'met_eireann_data/extracted/{folder}/{file}', 'r') as f2:\n",
    "                #         for line in f2:\n",
    "                            \n",
    "                print(file, station_name, Latitude, Longitude, Station_Height, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cfa382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FINNER', 'Latitude:54.494', 'Longitude: -8.243', '33 M', 'hly2075.csv') 15 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir'],\n",
      "      dtype='object')\n",
      "('MALIN HEAD', 'Latitude:55.372', 'Longitude: -7.339', '20 M', 'hly1575.csv') 21 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir', 'ww', 'w',\n",
      "       'sun', 'vis', 'clht', 'clamt'],\n",
      "      dtype='object')\n",
      "('MACE HEAD', 'Latitude:53.326', 'Longitude: -9.901', '21 M', 'hly275.csv') 15 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir'],\n",
      "      dtype='object')\n",
      "('MULLINGAR', 'Latitude:53.537', 'Longitude: -7.362', '101 M', 'hly875.csv') 15 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir'],\n",
      "      dtype='object')\n",
      "('NEWPORT', 'Latitude:53.924', 'Longitude: -9.573', '22 M', 'hly1175.csv') 15 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir'],\n",
      "      dtype='object')\n",
      "('PHOENIX PARK', 'Latitude:53.364', 'Longitude: -6.350', '48 M', 'hly175.csv') 11 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl'],\n",
      "      dtype='object')\n",
      "('SHANNON AIRPORT', 'Latitude:52.690', 'Longitude: -8.918', '15 M', 'hly518.csv') 21 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir', 'ww', 'w',\n",
      "       'sun', 'vis', 'clht', 'clamt'],\n",
      "      dtype='object')\n",
      "('MARKREE', 'Latitude:54.175', 'Longitude: -8.456', '34 M', 'hly1275.csv') 11 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl'],\n",
      "      dtype='object')\n",
      "('ATHENRY', 'Latitude:53.289', 'Longitude: -8.786', '40 M', 'hly1875.csv') 15 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir'],\n",
      "      dtype='object')\n",
      "('VALENTIA OBSERVATORY', 'Latitude:51.938', 'Longitude: -10.241', '24 M', 'hly2275.csv') 21 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir', 'ww', 'w',\n",
      "       'sun', 'vis', 'clht', 'clamt'],\n",
      "      dtype='object')\n",
      "('JOHNSTOWN CASTLE 2', 'Latitude:52.298', 'Longitude: -6.497', '62 M', 'hly1775.csv') 15 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir'],\n",
      "      dtype='object')\n",
      "('GURTEEN', 'Latitude:53.035', 'Longitude: -8.009', '75 M', 'hly1475.csv') 15 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir'],\n",
      "      dtype='object')\n",
      "('SHERKIN ISLAND', 'Latitude:51.476', 'Longitude: -9.428', '21 M', 'hly775.csv') 15 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir'],\n",
      "      dtype='object')\n",
      "('ROCHES POINT', 'Latitude:51.793', 'Longitude: -8.244', '40 M', 'hly1075.csv') 15 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
      "       'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check all of the column titles from each file to see if they are consistent\n",
    "columns = {}\n",
    "for df_list in dfs:\n",
    "    df = df_list[0]\n",
    "\n",
    "    print(df_list[1:],len(df.columns), df.columns)\n",
    "#     for col in df.columns:\n",
    "#         if col not in columns:\n",
    "#             columns[col] = 0\n",
    "#         columns[col] += 1\n",
    "\n",
    "# columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                date  ind  rain  ind.1  temp  ind.2  wetb  dewpt  vappr  rhum  \\\n",
      "0  01-may-1955 01:00    0   0.0      0   8.5      0   7.2    5.5    9.1  83.0   \n",
      "1  01-may-1955 02:00    0   0.0      0   8.2      0   7.2    6.1    9.3  85.0   \n",
      "2  01-may-1955 03:00    3   0.0      0   7.3      0   6.6    5.5    9.3  91.0   \n",
      "3  01-may-1955 04:00    3   0.0      0   7.8      0   7.2    6.1    9.6  91.0   \n",
      "4  01-may-1955 05:00    0   0.0      0   8.1      0   7.3    6.6    9.7  89.0   \n",
      "\n",
      "   ...  ind.3  wdsp  ind.4  wddir   ww    w  sun    vis   clht  clamt  \n",
      "0  ...    0.0  11.0    0.0  130.0  3.0  2.0  0.0  30000   40.0    7.0  \n",
      "1  ...    0.0  11.0    0.0  120.0  1.0  2.0  0.0  30000  100.0    6.0  \n",
      "2  ...    0.0   8.0    0.0  120.0  1.0  2.0  0.0  30000  220.0    5.0  \n",
      "3  ...    0.0  18.0    0.0  130.0  3.0  2.0  0.0  30000   90.0    7.0  \n",
      "4  ...    0.0   9.0    0.0  110.0  2.0  2.0  0.0  40000   90.0    7.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55a4a626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
      "/var/folders/_p/613_2b4n3p5_5kx0pkkwfw5w0000gs/T/ipykernel_53395/1752708584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Process date column to datetime object and filter to only include data from 2014 onwards\n",
    "# Add station name at the start and save station metadata in a separate csv file.\n",
    "# Convert rain, temp, wetb, dewpt, vappr, rhum, msl, wdsp, wddir, sun, vis, clht, clamt to float values if they are columns in the dataframe\n",
    "# If there are any non float values in these columns (e.g ' ' or '---') convert them to NaN\n",
    "# Save cleaned data to new csv files in a new folder titled cleaned_data and file name as station_name.csv\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "for df_list in dfs:\n",
    "    df, station_name, Latitude, Longitude, Station_Height, file = df_list\n",
    "\n",
    "    # Process date column to datetime object\n",
    "    df['date'] = pd.to_datetime(df['date'], format='mixed')\n",
    "    df = df[df['date'] >= datetime(2014, 1, 1)]\n",
    "\n",
    "    # clean columns and convert to numeric values \n",
    "    columns_to_convert = ['rain', 'temp', 'wetb', 'dewpt', 'vappr', 'rhum', 'msl', 'wdsp', 'wddir', 'sun', 'vis', 'clht', 'clamt']\n",
    "    for col in columns_to_convert:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    if not os.path.exists('met_eireann_data/cleaned_data'):\n",
    "        os.makedirs('met_eireann_data/cleaned_data')\n",
    "    \n",
    "    # write additional metadata to a separate txt file with the same name as the csv file\n",
    "    with open(f'met_eireann_data/cleaned_data/{station_name}_metadata.txt', 'w') as f:\n",
    "        f.write(f'Station Name: {station_name}\\n')\n",
    "        f.write(f'Latitude: {Latitude}\\n')\n",
    "        f.write(f'Longitude: {Longitude}\\n')\n",
    "        f.write(f'Station Height: {Station_Height}\\n')\n",
    "\n",
    "    df.to_csv(f'met_eireann_data/cleaned_data/{station_name}.csv', index=False)\n",
    "\n",
    "# 21 Index(['date', 'ind', 'rain', 'ind.1', 'temp', 'ind.2', 'wetb', 'dewpt',\n",
    "#        'vappr', 'rhum', 'msl', 'ind.3', 'wdsp', 'ind.4', 'wddir', 'ww', 'w',\n",
    "#        'sun', 'vis', 'clht', 'clamt'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8737326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all files from cleaned_data into a single dataframe with an additional column for station name\n",
    "# Work on exploratory data analysis and visualisation next\n",
    "# Key visualisations are time series plots of key variables (e.g temperature, wind speed, solar radiation) for each station broken up into years so as to be of a manageable size\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
